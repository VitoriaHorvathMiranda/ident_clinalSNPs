---
title: "Clinal SNPs Identification"
author: "Vitória"
date: '2023-03-03'
output: md_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(tidyverse)
library(qvalue)
library(knitr)
```

## SNP Calling

Inicialmente, os SNPs haviam sido identificados com o [snape-pooled](https://github.com/EmanueleRaineri/snape-pooled). Esse programa considera a qualidade e a profundidade do sequenciamento e devolve a frequência das bases de todas as posições e a "probabilidade" daquela posição ser realmente polimórfica. Mas havia um problema: as amostras, os pools, precisavam correr separadamente. Isso tornava muito difícil a comparação de um determinado SNP entre todas as populações, já que ele poderia estar fixado em algumas delas (e, portanto, não ser chamado nessas populações). Isso poderia ser resolvido se houvesse alguma forma de juntar os outputs deste programa e depois filtrar todas as posições que fossem polimórficas em pelo menos uma população. Mas os arquivos eram muito grandes e não havia como (pelo menos eu não consegui). 
  
A segunda opção foi chamar os SNPs com o [PoolSNP](). Esse também é um programa especializado em chamar os SNPs de pool-seq. Mas ele aceita várias populações como input e identifica os SNPs olhando para todas as populações como um todo. É um programa bastante prático, porque possibilita que limites mínimos de profundidade e qualidade sejam estabelecidos. Esses limites valem para todas as populações, assim, temos a garantia que estamos comparando regiões que podem ser comparadas. Por exemplo, ele não consideraria SNPs que nas populações de  2009/2010 estão com boa qualidade, mas que em 1997 estão com a profundidade de leitura muito baixa. Outros parâmetros incluem o mínimo de reads que o alelo alternativo deve ter para ser considerado polimórfico e a frequência mínima que o SNP deve ter (esses dois parâmetros são calculados com base em todas as populações). Além do vcf com todos os SNPs identificados, PoolSNP também retorna um output com todas as posições que não foram chamadas porque não passaram no controle de qualidade.
  
O PoolSNP foi rodado com os seguintes parâmetros:

```{bash, eval=F, echo=T}
bash /home/vitoria/PoolSNP/PoolSNP.sh\
    mpileup={input.mpileup}\
    reference={input.ref}\
    names=ESC97,CMD97B,WVT97,MFL97,RVA97,SVT09,CMD10,SNC10,JFL10,CMA97,HMA09,HMA17,MCT09,MCT17,MCT97\
    max-cov=0.98\
    min-cov=10\
    min-count=5\
    min-freq=0.005\
    miss-frac=0.1\
    jobs=24\
    BS=1\
    base-quality=20\
    allsites=0\

```

O vcf criado ficou assim: 

```{bash, echo=FALSE}

zcat "/dados/time_clines/data/seqs/calls/PoolSNP_mincount5_minfreq0.005_cov10.vcf.gz" | grep -v "##" | head

```

## Frequências e Número Efetivo de Cromossomos

Extraí as frequências e a profundidade de leitura de cada SNP, com o script [freq_extraction.R](https://github.com/VitoriaHorvathMiranda/ident_clinalSNPs/blob/main/freq_extraction.R). 


```{r, echo=FALSE}
kable(fread("/dados/time_clines/data/seqs/calls/freqs_and_depths_mincount5_minfreq0.005_cov10.tsv", nrows = 10))
```

Em seguida calculei o número efetivo de cromossomos com o script [n_chrom.R](https://github.com/VitoriaHorvathMiranda/ident_clinalSNPs/blob/main/n_chrom.R). Para fazer isso usei o número de cromossomos amostrado em cada população e a profundidade de leitura. O número de cromossomos amostrados em cada população estava na tabela de metadados e a profundidade de leitura foi extraída do vcf.

```{r, eval=F, echo=T}
freqs[, NE := ((1/depth) + (1/n_chrom))^-1]
```
```{r, echo=FALSE}
kable(fread("/dados/time_clines/data/seqs/align/NE_mincount5_minfreq0.005_cov10.tsv", nrows = 10))
```

Separei esse arquivo em outros três com base no ano em que a população foi coletada. Então no final formei três tabelas, uma com as populações de 1997, uma com as populações de 2009/2010 e uma última com as populações de 2017.


## Glm

Para identificar os SNPs clinais era preciso correr um GLM para cada SNP de cada período. Usei o mesmo GLM escolhido pelo Murillo, mas talvez isso possa ser debatido. É um modelo com a frequência dos SNPs como variável preditora e a latitude como variável resposta, com função de ligação binomial e pesado para o número efetivo de cromossomos [glm_script.R](https://github.com/VitoriaHorvathMiranda/ident_clinalSNPs/blob/main/glm_script.R)  

```{r, eval=F, echo=T}
nested_snps[, models := purrr::map(data, ~ glm(freq~latitude, 
                                               weights = NE,
                                               data = .x,
                                               family = binomial()))]
```

```{r, echo=FALSE, warning = FALSE}
NE_table <- fread(file = "/dados/time_clines/output/SNPs/joined97_mincount5_minfreq0.005_cov10.tsv")
NE_table <- NE_table[CHROM == "2L",]
NE_table[, position2 := paste(CHROM, POS, sep = ":")]
NE_table <- NE_table[, !c("CHROM", "POS")]

group_nest_dt <- function(dt, ..., .key = "data"){
  stopifnot(is.data.table(dt))
  by <- substitute(list(...))
  dt <- dt[, list(list(.SD)), by = eval(by)]
  setnames(dt, old = "V1", new = .key)
  dt
}

nested_snps <- NE_table[,group_nest_dt(.SD, position2)]

nested_snps <- nested_snps[1:10,]
nested_snps[, models := purrr::map(data, ~ glm(freq~latitude, 
                                               weights = NE,
                                               data = .x,
                                               family = binomial()))]

nested_snps
```

olhando para um modelo:
```{r}
pluck(nested_snps[[3]]) %>% pluck(1)

nested_snps[, summary := purrr::map(models, 
                                        ~summary(.x))]
pluck(nested_snps[[4]]) %>% pluck(1)
```

Então extrai o coeficiente de inclinação e o p-valor associado ao coeficiente de inclinação de cada glm:
```{r}
#gets lat coefficient
nested_snps[, coefficients := purrr::map_dbl(models, ~coef(.x) %>% pluck("latitude"))]

#gets p-value
nested_snps[, p_value := purrr::map_dbl(models, 
                                         ~summary(.x) %>% 
                                           pluck("coefficients") %>% pluck(8))]
nested_snps
```

## P-valores

Decidi fazer um histograma dos p-valores para entender como eles estavam distribuídos, e notei que tanto a distribuição dos SNPs de 1997 quanto as de 2009/2010, havia uma excesso de SNPs com p-valores muito altos.

```{r, echo=FALSE, warning = FALSE, message = FALSE}
SNPs_97_cov10 <- fread("/dados/time_clines/output/SNPs/p-values_97_mincount5_minfreq0.005_cov10.tsv")
SNPs_0910_cov10 <- fread("/dados/time_clines/output/SNPs/p-values_0910_mincount5_minfreq0.005_cov10.tsv")

plot1 <- SNPs_97_cov10 %>%
  ggplot() +
  geom_histogram(aes(p_value))+
  labs(x = "p-value", title = "1997",
       caption = "min-freq = 0.005, min-cov = 10, min-count = 5") +
  theme_minimal()

plot2 <- SNPs_0910_cov10 %>%
  ggplot() +
  geom_histogram(aes(p_value)) +
  labs(x = "p-value", title = "2009/2010",
       caption = "min-freq = 0.005, min-cov = 10, min-count = 5") +
  theme_minimal()

plot1
plot2

```

A minha teoria para explicar esse comportamento é de que existia um excesso de SNPs raros, com baixa frequência e presentes em uma ou poucas populações, e que, quando eram testados pelo modelo, não eram nada clinais (por isso os p-valores altos). Acho que é até possível argumentar que alguns desses SNPs nem sejam SNPs verdadeiros, mas sim erros de sequenciamento. Isso porque, como são muitos SNPs, mesmo com um filtro de qualidade de base 20 (probabilidade de erro de 1 a cada 1000), não é possível de se livrar de todos os erros. Como inicialmente eu tinha chamado os SNPs com um filtro de frequência de 0.5%, resolvi chamar novamente os SNPs, mas dessa vez com um filtro de 1% de frequência. Também aumentei outros filtros, a cobertura mínima exigida passou a ser de 15 (antes era de 10) e a base alternativa deveria ser lida pelo menos 10 vezes para ser considerada. O Comando para isso ficou assim:

```{bash, eval=F, echo=T}
bash /home/vitoria/PoolSNP/PoolSNP.sh\
    mpileup={input.mpileup}\
    reference={input.ref}\
    names=ESC97,CMD97B,WVT97,MFL97,RVA97,SVT09,CMD10,SNC10,JFL10,CMA97,HMA09,HMA17,MCT09,MCT17,MCT97\
    max-cov=0.98\
    min-cov=15\
    min-count=10\
    min-freq=0.01\
    miss-frac=0.1\
    jobs=24\
    BS=1\
    base-quality=20\
    allsites=0\
    output={params.outdir}
```

Corri todo o pipeline novamente e o número de SNPs com p-valores altos diminuiu consideravelmente:

```{r, echo=FALSE, warning = FALSE, message = FALSE}
SNPs_97_cov15 <- fread("/dados/time_clines/output/SNPs/p-values_97_mincount10_minfreq0.01_cov15.tsv")
SNPs_0910_cov15 <- fread("/dados/time_clines/output/SNPs/p-values_0910_mincount10_minfreq0.01_cov15.tsv")

SNPs_97_cov15 %>%
  ggplot() +
  geom_histogram(aes(p_value)) +
  labs(x = "p-value", title = "1997",
       caption = "min-freq = 0.01, min-cov = 15, min-count = 10") +
  theme_minimal()

SNPs_0910_cov15 %>%
  ggplot() +
  geom_histogram(aes(p_value))+
  labs(x = "p-value", title = "2009/2010",
       caption = "min-freq = 0.01, min-cov = 15, min-count = 10") +
  theme_minimal()

```

## P-value cutoff

Existe ainda outro script ([FDR_script.R](https://github.com/VitoriaHorvathMiranda/ident_clinalSNPs/blob/main/FDR_script.R)) que escrevi para calcular o p-valor para um dado FDR. Isso foi feito com o pacote [qvalue](https://github.com/StoreyLab/qvalue), criado pelos autores do paper [Storey and Tibshirani, 2003](https://www.pnas.org/doi/abs/10.1073/pnas.1530509100). 

## Manhattan Plots

Eu queria ver como esses p-valores estão distribuídos no genoma. Então fiz Manhattan plots para 1997 e 2009/2010. Para fazer isso só usei os resultados dos glms que corri com a segunda chamada de SNPs (com o filtro de 1% de frequência e cobertura mínima de 15).

```{r, echo=FALSE}
SNPs_97_cov15[, c("CHROM", "POS") := tstrsplit(position2, ":", fixed = TRUE)]

SNPs_97_cov15 <- SNPs_97_cov15[, .(CHROM, POS, p_value)]
SNPs_97_cov15[, POS := as.double(POS)]
SNPs_97_cov15[, ID := .I]

axisdf <-  SNPs_97_cov15 %>% group_by(CHROM) %>% summarize(center=( max(ID) + min(ID) ) / 2 )

#get FDR cutof
Pvalue_97_cov15 <- SNPs_97_cov15$p_value
qobj_97_cov15 <- qvalue(p = Pvalue_97_cov15)

#cutoff 0.1%
p_value_cutoff_0.1 <- max(qobj_97_cov15$pvalues[qobj_97_cov15$qvalues <= 0.1])

#cutoff 0.01%
p_value_cutoff_0.01 <- max(qobj_97_cov15$pvalues[qobj_97_cov15$qvalues <= 0.01])

#cutoff 0.05%
p_value_cutoff_0.005 <- max(qobj_97_cov15$pvalues[qobj_97_cov15$qvalues <= 0.005])

#manhattan plot manual

SNPs_97_cov15 %>%
  ggplot(aes(x = ID, y =-log10(p_value))) +
  geom_point(aes(color=as.factor(CHROM)), alpha=0.8, size=0.9) +
  geom_line(aes(y = -log10(p_value_cutoff_0.1)), color = "green") +
  geom_line(aes(y = -log10(p_value_cutoff_0.01)), color = "blue") +
  geom_line(aes(y = -log10(p_value_cutoff_0.005)), color = "red") +
  geom_text(aes(x = max(ID)+10,
                y = -log10(p_value_cutoff_0.1) + 0.25,
                label = "FDR 10%"),
            size = 2.5, color = "green") +
  geom_text(aes(x = max(ID)+10,
                y = -log10(p_value_cutoff_0.01) + 0.25,
                label = "FDR 1%"),
            size = 2.5, color = "blue") +
  geom_text(aes(x = max(ID)+10,
                y = -log10(p_value_cutoff_0.005) + 0.25,
                label = "FDR 0.5%"),
            size = 2.5, color = "red") +
  scale_color_manual(values = rep(c("lavender", "lavenderblush1"), 5)) +
  scale_x_continuous(label = axisdf$CHROM, breaks= axisdf$center) +
  scale_y_continuous(expand = c(0, 0)) +
  theme_bw() +
  theme( 
    legend.position="none",
    panel.border = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank()
  ) + 
  labs(title = "1997", y = "-log10(p-value)")

```

```{r, echo=FALSE}
SNPs_0910_cov15[, c("CHROM", "POS") := tstrsplit(position2, ":", fixed = TRUE)]

SNPs_0910_cov15 <- SNPs_0910_cov15[, .(CHROM, POS, p_value)]
SNPs_0910_cov15[, POS := as.double(POS)]
SNPs_0910_cov15[, ID := .I]

axisdf <-  SNPs_0910_cov15 %>% group_by(CHROM) %>% summarize(center=( max(ID) + min(ID) ) / 2 )

#get FDR cutof
Pvalue_0910_cov15 <- SNPs_0910_cov15$p_value
qobj_0910_cov15 <- qvalue(p = Pvalue_0910_cov15)

#cutoff 0.1%
p_value_cutoff_0.1 <- max(qobj_0910_cov15$pvalues[qobj_0910_cov15$qvalues <= 0.1])

#cutoff 0.01%
p_value_cutoff_0.01 <- max(qobj_0910_cov15$pvalues[qobj_0910_cov15$qvalues <= 0.01])

#cutoff 0.05%
p_value_cutoff_0.005 <- max(qobj_0910_cov15$pvalues[qobj_0910_cov15$qvalues <= 0.005])

#manhattan plot manual

SNPs_0910_cov15 %>%
  ggplot(aes(x = ID, y =-log10(p_value))) +
  geom_point(aes(color=as.factor(CHROM)), alpha=0.8, size=0.9) +
  geom_line(aes(y = -log10(p_value_cutoff_0.1)), color = "green") +
  geom_line(aes(y = -log10(p_value_cutoff_0.01)), color = "blue") +
  geom_line(aes(y = -log10(p_value_cutoff_0.005)), color = "red") +
  geom_text(aes(x = max(ID)+10,
                y = -log10(p_value_cutoff_0.1) + 0.25,
                label = "FDR 10%"),
            size = 2.5, color = "green") +
  geom_text(aes(x = max(ID)+10,
                y = -log10(p_value_cutoff_0.01) + 0.25,
                label = "FDR 1%"),
            size = 2.5, color = "blue") +
  geom_text(aes(x = max(ID)+10,
                y = -log10(p_value_cutoff_0.005) + 0.25,
                label = "FDR 0.5%"),
            size = 2.5, color = "red") +
  scale_color_manual(values = rep(c("lavender", "lavenderblush1"), 5)) +
  scale_x_continuous(label = axisdf$CHROM, breaks= axisdf$center) +
  scale_y_continuous(expand = c(0, 0)) +
  theme_bw() +
  theme( 
    legend.position="none",
    panel.border = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank()
  ) + 
  labs(title = "2009/2010", y = "-log10(p-value)")
```



